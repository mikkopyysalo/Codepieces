
# basic stuff. installing packages and creating the data frame
install.packages("tm")

install.packages("wordcloud")

library(tm)

library(wordcloud)

wttweets<-searchTwitter("#wisdomteeth",n=200,cainfo="cacert.pem")

df<-do.call("rbind", lapply(wttweets, as.data.frame)) 

dim(df) #check dimensions
df$text<-iconv(enc2utf8(df$text),sub="byte")

wtcorpus<-Corpus(VectorSource(df$text))

wtcorpus<-tm_map(wtcorpus,tolower, lazy=TRUE,mc.cores=1)

wtcorpus<-tm_map(wtcorpus,removePunctuation, lazy=TRUE,mc.cores=1)

wtcorpus<-tm_map(wtcorpus,removeNumbers, lazy=TRUE, mc.cores=1)

wtcorpus<-tm_map(wtcorpus,removeWords,stopwords("english"), lazy=TRUE,mc.cores=1)
wtcorpus<-tm_map(wtcorpus, function(x) iconv(x, to="UTF-8-MAC", sub="byte"),lazy=TRUE)


# building the document term matrix
wtdtm<-TermDocumentMatrix(wtcorpus, control=list(minWordLength=1)) #This doesnÂ´t work

# some association analyses
findFreqTerms(wtdtm,lowfreg=10)
findAssocs(wtdtm, "pain", 0.30) # which words are associated to the pain (awful..?)

# wordcloud
pilvi<-as.matrix(wtdtm)
cumulus<-sort(rowSums(pilvi), decreasing=TRUE)
nimet<-names(cumulus)
d<-data.frame(word=nimet, freq=cumulus)
wordcloud(d$word, d$freq, min.freq=3)

